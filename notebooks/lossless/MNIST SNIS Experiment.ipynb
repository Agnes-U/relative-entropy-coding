{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.models.mnist_vae import MNISTVAE\n",
    "from rec.core.utils import setup_logger\n",
    "\n",
    "import tensorflow as tf\n",
    "tfl = tf.keras.layers\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://github.com/tensorflow/tensorflow/issues/31135#issuecomment-516526113\n",
    "# Set CPU as available physical device\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../../models/relative-entropy-coding/empirical-bayes-experiments/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_save_dir = \"../../../../models/relative-entropy-coding/empirical-bayes-experiments/mnist/gaussian\"\n",
    "mog_save_dir = \"../../../../models/relative-entropy-coding/empirical-bayes-experiments/mnist/mog\"\n",
    "snis_save_dir = \"../../../../models/relative-entropy-coding/empirical-bayes-experiments/mnist/snis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored ../../../../models/relative-entropy-coding/empirical-bayes-experiments/mnist/gaussian/ckpt-110\n"
     ]
    }
   ],
   "source": [
    "gaussian_vae = MNISTVAE(name=\"gaussian_mnist_vae\", prior=tfd.Normal(loc=tf.zeros(50), scale=tf.ones(50)))\n",
    "\n",
    "gaussian_ckpt = tf.train.Checkpoint(model=gaussian_vae)\n",
    "\n",
    "gaussian_manager = tf.train.CheckpointManager(gaussian_ckpt, gaussian_save_dir, max_to_keep=3)\n",
    "\n",
    "gaussian_vae(tf.zeros([1, 28, 28, 1]))\n",
    "gaussian_ckpt.restore(gaussian_manager.latest_checkpoint)\n",
    "\n",
    "if gaussian_manager.latest_checkpoint:\n",
    "    print(f\"Restored {gaussian_manager.latest_checkpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored ../../../../models/relative-entropy-coding/empirical-bayes-experiments/mnist/mog/ckpt-1414\n"
     ]
    }
   ],
   "source": [
    "# Create MoG\n",
    "\n",
    "num_components = 100\n",
    "\n",
    "probs = tf.ones([50, num_components]) / num_components\n",
    "loc = tf.Variable(tf.random.uniform(shape=(num_components, 50), minval=-1., maxval=1.))\n",
    "log_scale = tf.Variable(tf.random.uniform(shape=(num_components, 50), minval=-1., maxval=1.))\n",
    "\n",
    "scale = 1e-5 + tf.nn.softplus(log_scale)\n",
    "\n",
    "components = [tfd.Normal(loc=loc[i, :], scale=scale[i, :]) for i in range(num_components)]\n",
    "\n",
    "mixture = tfd.Mixture(cat=tfd.Categorical(probs=probs),\n",
    "                      components=components)\n",
    "\n",
    "# Instantiate model\n",
    "mog_vae = MNISTVAE(name=\"mog_mnist_vae\", \n",
    "                   prior=mixture)\n",
    "\n",
    "mog_ckpt = tf.train.Checkpoint(model=mog_vae)\n",
    "\n",
    "mog_manager = tf.train.CheckpointManager(mog_ckpt, mog_save_dir, max_to_keep=3)\n",
    "\n",
    "mog_vae(tf.zeros([1, 28, 28, 1]))\n",
    "mog_ckpt.restore(mog_manager.latest_checkpoint)\n",
    "\n",
    "if mog_manager.latest_checkpoint:\n",
    "    print(f\"Restored {mog_manager.latest_checkpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tfds.load(\"binarized_mnist\",\n",
    "                    data_dir=\"/scratch/gf332/datasets/binarized_mnist\")\n",
    "\n",
    "test_ds = dataset[\"test\"]\n",
    "\n",
    "test_ds = test_ds.map(lambda x: tf.cast(x[\"image\"], tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IWAE lower bound:\n",
    "\n",
    "$$\n",
    "\\log p(x) \\geq \\mathbb{E}_{z_1,...,z_k \\sim q(z \\mid x)}\\left[ \\log\\left(\\frac1k \\sum_{i=1}^k \\frac{p(x, z_i)}{q(z_i\\mid x)}\\right)\\right]\n",
    "$$\n",
    "The right side is equal to\n",
    "$$\n",
    "\\mathbb{E}_{z_1,...,z_k \\sim q(z \\mid x)}\\left[ -\\log k + \\log \\sum_{i=1}^k\\exp\\left\\{\\log p(x \\mid z_i) + \\log p(z_i) - \\log q(z_i \\mid x)\\right\\} \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105f6508e2c649f9ae6431c299058c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "K = 5000\n",
    "num_samples = 100\n",
    "\n",
    "log_liks = []\n",
    "\n",
    "model = gaussian_vae\n",
    "\n",
    "for i in tqdm(test_ds.take(num_samples), total=num_samples):\n",
    "\n",
    "    reconstruction = model(i[None, ...])[0,...,0]\n",
    "\n",
    "    samples = tf.reshape(model.posterior.sample(K), [K, -1])\n",
    "\n",
    "    post_prob = model.posterior.log_prob(samples)\n",
    "    post_prob = tf.reduce_sum(post_prob, axis=1)\n",
    "\n",
    "    prior_prob = model.prior.log_prob(samples)\n",
    "    prior_prob = tf.reduce_sum(prior_prob, axis=1)\n",
    "\n",
    "    likelihood_loc = model.decoder(samples)\n",
    "    likelihood_dist = tfd.Bernoulli(probs=tf.clip_by_value(likelihood_loc, 1e-20, 1 - 1e-20))\n",
    "\n",
    "    likelihood = likelihood_dist.log_prob(i)\n",
    "    likelihood = tf.einsum(\"ijkl -> i\", likelihood)\n",
    "\n",
    "    log_weights = prior_prob + likelihood - post_prob \n",
    "\n",
    "    log_lik = tf.reduce_logsumexp(log_weights)\n",
    "    log_lik = log_lik - tf.math.log(tf.cast(K, tf.float32))\n",
    "\n",
    "    log_liks.append(log_lik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -89.2150\n",
      "Standard deviation: 22.7186\n"
     ]
    }
   ],
   "source": [
    "mean, var = tf.nn.moments(tf.convert_to_tensor(log_liks), axes=[0])\n",
    "\n",
    "print(f\"Mean: {mean:.4f}\")\n",
    "print(f\"Standard deviation: {tf.sqrt(var):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = tf.random.normal(shape=(5, 2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comps = tfd.Normal(loc=tf.zeros((3, 2, 2)), scale=tf.ones((3, 2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=193637, shape=(5, 3, 2, 2), dtype=float32, numpy=\n",
       "array([[[[-1.8075321 , -2.141438  ],\n",
       "         [-1.0765419 , -1.098341  ]],\n",
       "\n",
       "        [[-1.8075321 , -2.141438  ],\n",
       "         [-1.0765419 , -1.098341  ]],\n",
       "\n",
       "        [[-1.8075321 , -2.141438  ],\n",
       "         [-1.0765419 , -1.098341  ]]],\n",
       "\n",
       "\n",
       "       [[[-0.98604095, -1.0405747 ],\n",
       "         [-1.2297792 , -1.5500066 ]],\n",
       "\n",
       "        [[-0.98604095, -1.0405747 ],\n",
       "         [-1.2297792 , -1.5500066 ]],\n",
       "\n",
       "        [[-0.98604095, -1.0405747 ],\n",
       "         [-1.2297792 , -1.5500066 ]]],\n",
       "\n",
       "\n",
       "       [[[-1.2495228 , -0.9701338 ],\n",
       "         [-0.94274753, -2.5368283 ]],\n",
       "\n",
       "        [[-1.2495228 , -0.9701338 ],\n",
       "         [-0.94274753, -2.5368283 ]],\n",
       "\n",
       "        [[-1.2495228 , -0.9701338 ],\n",
       "         [-0.94274753, -2.5368283 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.9446475 , -1.7761207 ],\n",
       "         [-1.8741846 , -1.108798  ]],\n",
       "\n",
       "        [[-0.9446475 , -1.7761207 ],\n",
       "         [-1.8741846 , -1.108798  ]],\n",
       "\n",
       "        [[-0.9446475 , -1.7761207 ],\n",
       "         [-1.8741846 , -1.108798  ]]],\n",
       "\n",
       "\n",
       "       [[[-1.1918526 , -1.4695321 ],\n",
       "         [-1.2202878 , -2.1416664 ]],\n",
       "\n",
       "        [[-1.1918526 , -1.4695321 ],\n",
       "         [-1.2202878 , -2.1416664 ]],\n",
       "\n",
       "        [[-1.1918526 , -1.4695321 ],\n",
       "         [-1.2202878 , -2.1416664 ]]]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_comps.log_prob(test_batch[:, None, ...])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
