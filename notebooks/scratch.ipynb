{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from rec.models.resnet_vae import BidirectionalResNetVAE\n",
    "from rec.models.custom_modules import ReparameterizedConv2D, ReparameterizedConv2DTranspose, GDN\n",
    "from rec.models.pixel_cnn import PixelCNNResidualBlock\n",
    "\n",
    "from rec.coding.coder import GaussianCoder\n",
    "from rec.coding.samplers import ImportanceSampler\n",
    "\n",
    "from rec.models.large_resnet_vae import LargeResNetVAE\n",
    "\n",
    "from rec.io.entropy_coding import ArithmeticCoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://github.com/tensorflow/tensorflow/issues/31135#issuecomment-516526113\n",
    "# Set CPU as available physical device\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3, 4) (1, 2, 3, 4)\n",
      "tf.Tensor(2.3841858e-07, shape=(), dtype=float32)\n",
      "(1, 2, 3, 4) (1, 2, 3, 4)\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 2, 3, 4), dtype=tf.float32)\n",
    "y = GDN(inverse=False)(x)\n",
    "print(x.shape, y.shape)\n",
    "print(tf.reduce_max(tf.abs(y - x / tf.sqrt(1 + .1 * (x ** 2)))))\n",
    "\n",
    "x = tf.random.uniform((1, 2, 3, 4), dtype=tf.float32)\n",
    "y = GDN(inverse=True)(x)\n",
    "print(x.shape, y.shape)\n",
    "print(tf.reduce_max(tf.abs(y - x * tf.sqrt(1 + .1 * (x ** 2)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_indices = np.load(\"../block_indices.npy\", allow_pickle=True)\n",
    "\n",
    "block_sizes = list(map(len, block_indices))\n",
    "num_aux_vars = [list(map(len, block)) for block in block_indices]\n",
    "\n",
    "block0 = np.concatenate(block_indices[0] + [[-1]], axis=0) + 1\n",
    "block1 = np.concatenate(block_indices[1] + [[-1]], axis=0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,  70,  98,  95, 102, 104,  91,  93,  96,  97,  88,  95, 106,\n",
       "        94,  80,  90,  78, 110,  80,  80,  99])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques, counts = np.unique(block0, return_counts=True)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 19612.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tree\n",
      "Depth of symbol tree: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ac = ArithmeticCoder(counts, precision=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1847/1847 [00:00<00:00, 167149.53it/s]\n"
     ]
    }
   ],
   "source": [
    "code = ac.encode(block0)\n",
    "decoded = ac.decode_fast(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(decoded) == block0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_aux_vars = list(map(len, block_indices[0]))\n",
    "\n",
    "plt.hist(num_aux_vars, bins=30)\n",
    "\n",
    "num_aux_vars = list(map(len, block_indices[1]))\n",
    "\n",
    "plt.hist(num_aux_vars, bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\t\t       ckpt-2127.index\r\n",
      "ckpt-2126.data-00000-of-00002  ckpt-2128.data-00000-of-00002\r\n",
      "ckpt-2126.data-00001-of-00002  ckpt-2128.data-00001-of-00002\r\n",
      "ckpt-2126.index\t\t       ckpt-2128.index\r\n",
      "ckpt-2127.data-00000-of-00002  logs\r\n",
      "ckpt-2127.data-00001-of-00002\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../models/relative-entropy-coding/imagenet32/resnet_vae/gaussian/blocks_24/beta_1.000_lamb_0.100/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_dir = \"../../../models/relative-entropy-coding/imagenet32/resnet_vae/gaussian/blocks_24/beta_1.000_lamb_0.100/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model from ../../../models/relative-entropy-coding/imagenet32/resnet_vae/gaussian/blocks_24/beta_1.000_lamb_0.100/ckpt-2128\n"
     ]
    }
   ],
   "source": [
    "model = BidirectionalResNetVAE(use_iaf=False,\n",
    "                               num_res_blocks=24,\n",
    "                               deterministic_filters=160,\n",
    "                               stochastic_filters=32)\n",
    "\n",
    "model(tf.zeros((1, 32, 32, 3)))\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Create Checkpoints\n",
    "# -------------------------------------------------------------------------\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "\n",
    "manager = tf.train.CheckpointManager(ckpt, model_save_dir, max_to_keep=3)\n",
    "\n",
    "# Restore previous session\n",
    "ckpt.restore(manager.latest_checkpoint)\n",
    "if manager.latest_checkpoint:\n",
    "    print(f\"Restored model from {manager.latest_checkpoint}\")\n",
    "else:\n",
    "    print(\"Initializing model from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.swap_in_ema_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tfds.load(\"downsampled_imagenet/32x32\", data_dir=\"/scratch/gf332/datasets/imagenet32\")[\"validation\"]\n",
    "ds = ds.map(lambda x: tf.clip_by_value((tf.cast(x[\"image\"], tf.float32) + 0.5) / 256., 0.0, 1.0) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_test_images = 10000\n",
    "max_batch_size = 100\n",
    "test_images = 300\n",
    "\n",
    "batched_ds = ds.take(test_images).batch(max_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f506b561293047a897a3e3b30d7ba90c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate average (negative) ELBO on test dataset\n",
    "neg_elbos = []\n",
    "\n",
    "for img in tqdm(batched_ds.take(test_images), total=test_images // max_batch_size):\n",
    "    res = model(img)\n",
    "    \n",
    "    neg_elbo = -model.log_likelihood + model.kl_divergence(empirical=False, minimum_kl=0.)\n",
    "\n",
    "    neg_elbos.append(neg_elbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(13.757815, shape=(), dtype=float32) tf.Tensor(4.5859385, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "bpp = tf.reduce_mean(neg_elbos) / (32 * 32 * np.log(2))\n",
    "bppc = bpp / 3\n",
    "\n",
    "print(bpp, bppc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(13.529109, shape=(), dtype=float32) tf.Tensor(4.509703, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "bpp = tf.reduce_mean(neg_elbos) / (32 * 32 * np.log(2))\n",
    "bppc = bpp / 3\n",
    "\n",
    "print(bpp, bppc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 500\n",
      "KL divergence: 283.4400634765625\n",
      "Dimensions: 500\n",
      "KL divergence: 291.41802978515625\n"
     ]
    }
   ],
   "source": [
    "def get_t_p_gauss(filename, dims=1000):\n",
    "    t_mean = np.tile(np.load(filename + 'post_loc.npy')[0], 1 + dims // 50)[:dims]\n",
    "    t_scale = np.tile(np.load(filename + 'post_scale.npy')[0], 1 + dims // 50)[:dims]\n",
    "    p_mean = np.tile(np.load(filename + 'prior_loc.npy'), 1 + dims // 50)[:dims]\n",
    "    p_scale = np.tile(np.load(filename + 'prior_scale.npy'), 1 + dims // 50)[:dims]\n",
    "\n",
    "    ndims = p_mean.shape[0]\n",
    "    print('Dimensions: {}'.format(ndims))\n",
    "    p = tfp.distributions.Normal(loc=p_mean, scale=p_scale)\n",
    "    t = tfp.distributions.Normal(loc=t_mean, scale=t_scale)\n",
    "    print('KL divergence: {}'.format(tf.reduce_sum(tfp.distributions.kl_divergence(t, p))))\n",
    "    return t, p\n",
    "\n",
    "mnist_path = '/scratch/gf332/CWOQ/relative-entropy-coding/experimental_data/data_distributions/mnist/beta_1_latents_50/test/img_{}/'\n",
    "\n",
    "t_list = []\n",
    "p_list = []\n",
    "for i in range(2):\n",
    "    t, p = get_t_p_gauss(filename=mnist_path.format(i), dims=500)\n",
    "    t_list.append(t)\n",
    "    p_list.append(p)\n",
    "\n",
    "target_kl = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.coding.rejection_sampling import get_aux_distribution, preprocessing_auxiliary_ratios, get_conditionals\n",
    "from rec.coding.coder import get_auxiliary_coder, get_auxiliary_target, get_conditional_coder, get_conditional_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aux\n",
      "t loc diff: 0.0\n",
      "t scale diff: 2.9802322387695312e-08\n",
      "p loc diff: 0.0\n",
      "p scale diff: 0.0\n",
      "\n",
      " cond\n",
      "t loc diff: 0.0\n",
      "t scale diff: 0.0\n",
      "p loc diff: 0.0\n",
      "p scale diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "aux_var = 0.1\n",
    "\n",
    "t1, p1 = get_aux_distribution(t_list[0],\n",
    "                     p_list[0],\n",
    "                     aux_var)\n",
    "\n",
    "t2 = get_auxiliary_target(t_list[0],\n",
    "                          p_list[0],\n",
    "                          aux_var)\n",
    "p2 = get_auxiliary_coder(p_list[0],\n",
    "                         aux_var)\n",
    "\n",
    "print(\"aux\")\n",
    "print(f\"t loc diff: {tf.reduce_max(tf.abs(t1.loc - t2.loc))}\")\n",
    "print(f\"t scale diff: {tf.reduce_max(tf.abs(t1.scale - t2.scale))}\")\n",
    "\n",
    "print(f\"p loc diff: {tf.reduce_max(tf.abs(p1.loc - p2.loc))}\")\n",
    "print(f\"p scale diff: {tf.reduce_max(tf.abs(p1.scale - p2.scale))}\")\n",
    "\n",
    "aux_samp = t2.sample()\n",
    "\n",
    "tc1, pc1 = get_conditionals(t_list[0],\n",
    "                            p_list[0],\n",
    "                            aux_var,\n",
    "                            aux_samp)\n",
    "\n",
    "tc2 = get_conditional_target(t_list[0],\n",
    "                            p_list[0],\n",
    "                            aux_var,\n",
    "                            aux_samp)\n",
    "\n",
    "pc2 = get_conditional_coder(p_list[0],\n",
    "                            aux_var,\n",
    "                            aux_samp)\n",
    "\n",
    "print(\"\\n cond\")\n",
    "print(f\"t loc diff: {tf.reduce_max(tf.abs(tc1.loc - tc2.loc))}\")\n",
    "print(f\"t scale diff: {tf.reduce_max(tf.abs(tc1.scale - tc2.scale))}\")\n",
    "\n",
    "print(f\"p loc diff: {tf.reduce_max(tf.abs(pc1.loc - pc2.loc))}\")\n",
    "print(f\"p scale diff: {tf.reduce_max(tf.abs(pc1.scale - pc2.scale))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aux_ratios = np.array([0.68339353, 0.54674925, 0.46513237, 0.4246385,  0.39013079, 0.37761325])\n",
    "aux_ratios = preprocessing_auxiliary_ratios(t_list, p_list, target_kl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
