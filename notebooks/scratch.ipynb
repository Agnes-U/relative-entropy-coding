{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from rec.models.resnet_vae import BidirectionalResNetVAE\n",
    "from rec.models.custom_modules import ReparameterizedConv2D, ReparameterizedConv2DTranspose\n",
    "from rec.models.pixel_cnn import PixelCNNResidualBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://github.com/tensorflow/tensorflow/issues/31135#issuecomment-516526113\n",
    "# Set CPU as available physical device\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\t\t       ckpt-2127.index\r\n",
      "ckpt-2126.data-00000-of-00002  ckpt-2128.data-00000-of-00002\r\n",
      "ckpt-2126.data-00001-of-00002  ckpt-2128.data-00001-of-00002\r\n",
      "ckpt-2126.index\t\t       ckpt-2128.index\r\n",
      "ckpt-2127.data-00000-of-00002  logs\r\n",
      "ckpt-2127.data-00001-of-00002\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../models/relative-entropy-coding/imagenet32/resnet_vae/gaussian/blocks_24/beta_1.000_lamb_0.100/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_dir = \"../../../models/relative-entropy-coding/imagenet32/resnet_vae/gaussian/blocks_24/beta_1.000_lamb_0.100/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored model from ../../../models/relative-entropy-coding/imagenet32/resnet_vae/gaussian/blocks_24/beta_1.000_lamb_0.100/ckpt-2128\n"
     ]
    }
   ],
   "source": [
    "model = BidirectionalResNetVAE(use_iaf=False,\n",
    "                               num_res_blocks=24,\n",
    "                               deterministic_filters=160,\n",
    "                               stochastic_filters=32)\n",
    "\n",
    "model(tf.zeros((1, 32, 32, 3)))\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Create Checkpoints\n",
    "# -------------------------------------------------------------------------\n",
    "ckpt = tf.train.Checkpoint(model=model)\n",
    "\n",
    "manager = tf.train.CheckpointManager(ckpt, model_save_dir, max_to_keep=3)\n",
    "\n",
    "# Restore previous session\n",
    "ckpt.restore(manager.latest_checkpoint)\n",
    "if manager.latest_checkpoint:\n",
    "    print(f\"Restored model from {manager.latest_checkpoint}\")\n",
    "else:\n",
    "    print(\"Initializing model from scratch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.swap_in_ema_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tfds.load(\"downsampled_imagenet/32x32\", data_dir=\"/scratch/gf332/datasets/imagenet32\")[\"validation\"]\n",
    "ds = ds.map(lambda x: tf.clip_by_value((tf.cast(x[\"image\"], tf.float32) + 0.5) / 256., 0.0, 1.0) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_test_images = 10000\n",
    "max_batch_size = 100\n",
    "test_images = 300\n",
    "\n",
    "batched_ds = ds.take(test_images).batch(max_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f506b561293047a897a3e3b30d7ba90c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate average (negative) ELBO on test dataset\n",
    "neg_elbos = []\n",
    "\n",
    "for img in tqdm(batched_ds.take(test_images), total=test_images // max_batch_size):\n",
    "    res = model(img)\n",
    "    \n",
    "    neg_elbo = -model.log_likelihood + model.kl_divergence(empirical=False, minimum_kl=0.)\n",
    "\n",
    "    neg_elbos.append(neg_elbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(13.757815, shape=(), dtype=float32) tf.Tensor(4.5859385, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "bpp = tf.reduce_mean(neg_elbos) / (32 * 32 * np.log(2))\n",
    "bppc = bpp / 3\n",
    "\n",
    "print(bpp, bppc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(13.529109, shape=(), dtype=float32) tf.Tensor(4.509703, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "bpp = tf.reduce_mean(neg_elbos) / (32 * 32 * np.log(2))\n",
    "bppc = bpp / 3\n",
    "\n",
    "print(bpp, bppc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 500\n",
      "KL divergence: 283.4400634765625\n",
      "Dimensions: 500\n",
      "KL divergence: 291.41802978515625\n"
     ]
    }
   ],
   "source": [
    "def get_t_p_gauss(filename, dims=1000):\n",
    "    t_mean = np.tile(np.load(filename + 'post_loc.npy')[0], 1 + dims // 50)[:dims]\n",
    "    t_scale = np.tile(np.load(filename + 'post_scale.npy')[0], 1 + dims // 50)[:dims]\n",
    "    p_mean = np.tile(np.load(filename + 'prior_loc.npy'), 1 + dims // 50)[:dims]\n",
    "    p_scale = np.tile(np.load(filename + 'prior_scale.npy'), 1 + dims // 50)[:dims]\n",
    "\n",
    "    ndims = p_mean.shape[0]\n",
    "    print('Dimensions: {}'.format(ndims))\n",
    "    p = tfp.distributions.Normal(loc=p_mean, scale=p_scale)\n",
    "    t = tfp.distributions.Normal(loc=t_mean, scale=t_scale)\n",
    "    print('KL divergence: {}'.format(tf.reduce_sum(tfp.distributions.kl_divergence(t, p))))\n",
    "    return t, p\n",
    "\n",
    "mnist_path = '/scratch/gf332/CWOQ/relative-entropy-coding/experimental_data/data_distributions/mnist/beta_1_latents_50/test/img_{}/'\n",
    "\n",
    "t_list = []\n",
    "p_list = []\n",
    "for i in range(2):\n",
    "    t, p = get_t_p_gauss(filename=mnist_path.format(i), dims=500)\n",
    "    t_list.append(t)\n",
    "    p_list.append(p)\n",
    "\n",
    "target_kl = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rec.coding.rejection_sampling import get_aux_distribution, preprocessing_auxiliary_ratios, get_conditionals\n",
    "from rec.coding.coder import get_auxiliary_coder, get_auxiliary_target, get_conditional_coder, get_conditional_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aux\n",
      "t loc diff: 0.0\n",
      "t scale diff: 2.9802322387695312e-08\n",
      "p loc diff: 0.0\n",
      "p scale diff: 0.0\n",
      "\n",
      " cond\n",
      "t loc diff: 0.0\n",
      "t scale diff: 0.0\n",
      "p loc diff: 0.0\n",
      "p scale diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "aux_var = 0.1\n",
    "\n",
    "t1, p1 = get_aux_distribution(t_list[0],\n",
    "                     p_list[0],\n",
    "                     aux_var)\n",
    "\n",
    "t2 = get_auxiliary_target(t_list[0],\n",
    "                          p_list[0],\n",
    "                          aux_var)\n",
    "p2 = get_auxiliary_coder(p_list[0],\n",
    "                         aux_var)\n",
    "\n",
    "print(\"aux\")\n",
    "print(f\"t loc diff: {tf.reduce_max(tf.abs(t1.loc - t2.loc))}\")\n",
    "print(f\"t scale diff: {tf.reduce_max(tf.abs(t1.scale - t2.scale))}\")\n",
    "\n",
    "print(f\"p loc diff: {tf.reduce_max(tf.abs(p1.loc - p2.loc))}\")\n",
    "print(f\"p scale diff: {tf.reduce_max(tf.abs(p1.scale - p2.scale))}\")\n",
    "\n",
    "aux_samp = t2.sample()\n",
    "\n",
    "tc1, pc1 = get_conditionals(t_list[0],\n",
    "                            p_list[0],\n",
    "                            aux_var,\n",
    "                            aux_samp)\n",
    "\n",
    "tc2 = get_conditional_target(t_list[0],\n",
    "                            p_list[0],\n",
    "                            aux_var,\n",
    "                            aux_samp)\n",
    "\n",
    "pc2 = get_conditional_coder(p_list[0],\n",
    "                            aux_var,\n",
    "                            aux_samp)\n",
    "\n",
    "print(\"\\n cond\")\n",
    "print(f\"t loc diff: {tf.reduce_max(tf.abs(tc1.loc - tc2.loc))}\")\n",
    "print(f\"t scale diff: {tf.reduce_max(tf.abs(tc1.scale - tc2.scale))}\")\n",
    "\n",
    "print(f\"p loc diff: {tf.reduce_max(tf.abs(pc1.loc - pc2.loc))}\")\n",
    "print(f\"p scale diff: {tf.reduce_max(tf.abs(pc1.scale - pc2.scale))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aux_ratios = np.array([0.68339353, 0.54674925, 0.46513237, 0.4246385,  0.39013079, 0.37761325])\n",
    "aux_ratios = preprocessing_auxiliary_ratios(t_list, p_list, target_kl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
